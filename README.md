# ğŸ“š Supabase RAG App with Hugging Face LLM

This project is a **Retrieval-Augmented Generation (RAG)** application built using:

- ğŸ§  **Hugging Face LLMs** (via `langchain-huggingface`)
- ğŸ“¦ **Supabase PostgreSQL** (for vector embeddings & document storage)
- ğŸ“„ **PDF/Text Document Upload**
- ğŸ” **LangChain** for chaining LLM + retriever
- ğŸ¯ **Streamlit** frontend for live Q&A
- ğŸ§¬ **Sentence-Transformers** for embedding generation

## ğŸš€ Features

- Upload PDF/text files and convert them to dense vector embeddings.
- Store embeddings + metadata in Supabase (PostgreSQL + pgvector).
- Ask natural-language questions based on your uploaded documents.
- Answers are generated by a Hugging Face-hosted LLM using context retrieved from Supabase.
- View sources along with the answer.

## ğŸ› ï¸ Tech Stack

| Component         | Description                           |
|------------------|---------------------------------------|
| ğŸ§  LLM            | Hugging Face Hub (e.g., Mistral, Falcon) |
| ğŸ§¬ Embeddings     | `sentence-transformers/all-MiniLM-L6-v2` |
| ğŸ“¦ Vector Store   | Supabase DB (pgvector)                |
| ğŸ”— LangChain      | RAG chain + retriever orchestration   |
| ğŸŒ Frontend       | Streamlit                             |

---

âš™ï¸ Setup Instructions

1. Clone Repository

git clone https://github.com/your-username/supabase-rag-app.git
cd supabase-rag-app

2. Create .env File

Create a .env file with:

SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
HUGGINGFACEHUB_API_TOKEN=your_hf_token

3. Install Dependencies

pip install -r requirements.txt

4. Create documents Table in Supabase

create extension if not exists vector;

create table if not exists documents (
  id uuid primary key default gen_random_uuid(),
  content text,
  metadata jsonb,
  embedding vector(384)
);

5. Add match_documents Function

create or replace function match_documents (
  query_embedding vector(384),
  match_count int default 5,
  match_threshold float default 0.7
)
returns table (
  id uuid,
  content text,
  metadata jsonb,
  embedding vector(384),
  similarity float
)
language sql stable
as $$
  select *, 1 - (documents.embedding <=> query_embedding) as similarity
  from documents
  where 1 - (documents.embedding <=> query_embedding) > match_threshold
  order by documents.embedding <=> query_embedding
  limit match_count;
$$;

ğŸš€ Run Application

Step 1: Upload PDFs and store embeddings

python uploader.py

Step 2: Launch the Streamlit interface

streamlit run main.py

ğŸ§  Models

Embeddings: sentence-transformers/all-MiniLM-L6-v2
LLM (configurable): e.g. Qwen/Qwen1.5-0.5B, mistralai/Mistral-7B-Instruct-v0.2

ğŸ›¡ï¸ Notes

Ensure pgvector is enabled in your Supabase instance.
Avoid uploading files with null bytes (\u0000).
Hugging Face models >10GB are not supported on hf-inference endpoints.



